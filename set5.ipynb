{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "set5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPP/xPjdgADJBzReluc7pZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverwsd/finance/blob/master/set5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49uzWiP40E42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import scipy.optimize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuuKsachnuGo",
        "colab_type": "code",
        "outputId": "9b677a61-d089-4f72-fad3-c6a130b74686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "from io import StringIO\n",
        "import csv\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/oliverwsd/finance/master/monthly_factors.csv'\n",
        "factors = pd.read_csv(url)\n",
        "factors.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>rm</th>\n",
              "      <th>rf</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>WML</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196207</td>\n",
              "      <td>-5.53</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-1.05</td>\n",
              "      <td>2.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>196208</td>\n",
              "      <td>6.11</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-5.50</td>\n",
              "      <td>-1.63</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>196209</td>\n",
              "      <td>-6.32</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2.26</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>196210</td>\n",
              "      <td>-2.03</td>\n",
              "      <td>0.24</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>196211</td>\n",
              "      <td>19.29</td>\n",
              "      <td>0.24</td>\n",
              "      <td>-0.87</td>\n",
              "      <td>-9.73</td>\n",
              "      <td>-10.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     date     rm    rf   SMB   HML    WML\n",
              "0  196207  -5.53  0.25 -0.29 -1.05   2.38\n",
              "1  196208   6.11  0.25 -5.50 -1.63   0.80\n",
              "2  196209  -6.32  0.26  2.26  0.14   1.94\n",
              "3  196210  -2.03  0.24 -3.12  1.13   1.14\n",
              "4  196211  19.29  0.24 -0.87 -9.73 -10.36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMOlu-3vnuk5",
        "colab_type": "code",
        "outputId": "dac13937-460b-4f28-c916-307b5429f829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#factors         = pd.read_csv('monthly_factors.csv')\n",
        "factors['date'] = pd.to_datetime(factors['date'], format ='%Y%m') # Convert date column to the datetime data type\n",
        "factors['rm_excess'] = factors['rm'] - factors['rf']\n",
        "factors = factors[['date', 'rm_excess', 'rf']]  # We'll only use market excess returns and riskfree rate here\n",
        "factors[['rm_excess', 'rf']] /= 100  # Bring numbers to actual values\n",
        "factors.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>rm_excess</th>\n",
              "      <th>rf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1962-07-01</td>\n",
              "      <td>-0.0578</td>\n",
              "      <td>0.0025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1962-08-01</td>\n",
              "      <td>0.0586</td>\n",
              "      <td>0.0025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1962-09-01</td>\n",
              "      <td>-0.0658</td>\n",
              "      <td>0.0026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1962-10-01</td>\n",
              "      <td>-0.0227</td>\n",
              "      <td>0.0024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1962-11-01</td>\n",
              "      <td>0.1905</td>\n",
              "      <td>0.0024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date  rm_excess      rf\n",
              "0 1962-07-01    -0.0578  0.0025\n",
              "1 1962-08-01     0.0586  0.0025\n",
              "2 1962-09-01    -0.0658  0.0026\n",
              "3 1962-10-01    -0.0227  0.0024\n",
              "4 1962-11-01     0.1905  0.0024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5hKXBWoeMo",
        "colab_type": "code",
        "outputId": "75e4bff2-01fd-456a-e559-fca84c279e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        }
      },
      "source": [
        "# Task 1: Estimate AR(1)-ARCH(1) via 2-pass estimation\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# We start by estimating the AR(1)-ARCH(1) via a two-pass estimation approach, that is,\n",
        "# we first estimate the AR model via OLS, then calculate the residuals of that AR(1)\n",
        "# model and use them to estimate the ARCH(1) part via OLS.\n",
        "#\n",
        "# Estimate the AR(1) model for market excess returns via OLS.\n",
        "#\n",
        "# Note: 'ar_model' should contain the OLS regression result object (after fitting)\n",
        "#\n",
        "# IMPORTANT: Use the constant as first variable in the regression. This also applies to the\n",
        "#            next regression!\n",
        "\n",
        "X1 = pd.DataFrame()\n",
        "rm_excess_x = list(factors['rm_excess'])\n",
        "rm_excess_y = list(factors['rm_excess'])\n",
        "X1['alpha'] = np.ones(len(factors['rm_excess'])-1)\n",
        "X1['beta'] = rm_excess_x[:-1]\n",
        "Y1 = rm_excess_y[1:]\n",
        "ar_model = sm.OLS(Y1,X1).fit()\n",
        "\n",
        "print(ar_model.summary())\n",
        "\n",
        "\n",
        "# Now, we attack the ARCH(1) part. First, compute the residuals of the AR(1) model that\n",
        "# you just fitted.\n",
        "#\n",
        "ar_model_resid = list(rm_excess_y[1:]- (ar_model.params[0]+factors['rm_excess'][0:-1]*ar_model.params[1]))\n",
        "\n",
        "\n",
        "\n",
        "# Recall, an ARCH(1) model reads\n",
        "#     \\sigma_t^2 = a + b * \\epsilon_{t-1}^2\n",
        "# with \\sigma_t^2 being the variance of \\epsilon_t and \\epsilon_t is the residual of\n",
        "# the AR(1) model. We now use \\epsilon_t^2 as a very rough measurement for\n",
        "# \\sigma_t^2 (i.e. just replace \\sigma_t^2 in the equation above with \\epsilon_t^2)\n",
        "# and estimate the model via OLS.\n",
        "#\n",
        "# Please do so next.\n",
        "#\n",
        "# Note: 'arch_model' should contain the OLS regression result object (after fitting)\n",
        "squared_resid = list(map(lambda num:num*num, ar_model_resid))\n",
        "X2 = pd.DataFrame()\n",
        "X2['a']= np.ones(len(factors['rm_excess'])-2)\n",
        "X2['b'] = squared_resid[:-1]\n",
        "arch_model = sm.OLS(squared_resid[1:],X2).fit()\n",
        "print(arch_model.summary())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.011\n",
            "Model:                            OLS   Adj. R-squared:                  0.009\n",
            "Method:                 Least Squares   F-statistic:                     6.605\n",
            "Date:                Fri, 17 Jan 2020   Prob (F-statistic):             0.0104\n",
            "Time:                        10:19:26   Log-Likelihood:                 964.88\n",
            "No. Observations:                 617   AIC:                            -1926.\n",
            "Df Residuals:                     615   BIC:                            -1917.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "alpha          0.0038      0.002      1.833      0.067      -0.000       0.008\n",
            "beta           0.1030      0.040      2.570      0.010       0.024       0.182\n",
            "==============================================================================\n",
            "Omnibus:                       39.880   Durbin-Watson:                   1.989\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              110.050\n",
            "Skew:                          -0.281   Prob(JB):                     1.27e-24\n",
            "Kurtosis:                       4.991   Cond. No.                         19.6\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.010\n",
            "Model:                            OLS   Adj. R-squared:                  0.009\n",
            "Method:                 Least Squares   F-statistic:                     6.415\n",
            "Date:                Fri, 17 Jan 2020   Prob (F-statistic):             0.0116\n",
            "Time:                        10:19:26   Log-Likelihood:                 2377.1\n",
            "No. Observations:                 616   AIC:                            -4750.\n",
            "Df Residuals:                     614   BIC:                            -4741.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "a              0.0023      0.000      9.996      0.000       0.002       0.003\n",
            "b              0.1017      0.040      2.533      0.012       0.023       0.181\n",
            "==============================================================================\n",
            "Omnibus:                      620.454   Durbin-Watson:                   2.009\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            23100.551\n",
            "Skew:                           4.678   Prob(JB):                         0.00\n",
            "Kurtosis:                      31.504   Cond. No.                         195.\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kbFqpa4wuz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "2f3e84ab-92c0-44d5-eb77-2cc2dbfe6398"
      },
      "source": [
        "# Task 2: MLE estimation of AR(1)-ARCH(1) model\n",
        "# ---------------------------------------------\n",
        "\n",
        "# The 2-pass OLS estimation does not generally lead to parameter estimates that maximize\n",
        "# the (log-)likelihood of the model. Such parameters must be identified via numerical\n",
        "# optimization. For that, we assume that excess returns r_t are distributed\n",
        "# normally, with mean \\mu_t and volatility \\sigma_t. Recall that the likelihood equation\n",
        "# for the normal distribution reads:\n",
        "#\n",
        "#   L(r_t) = (1 / (2 * \\pi * \\sigma_t^2)^0.5) * e^(-(r_t - \\mu_t)^2 / (2 * \\sigma_t^2))\n",
        "#\n",
        "# This is the likelihood for a single r_t. To get the likelihood of the full time\n",
        "# series of r_t, we have to multiply the probabilities:\n",
        "#\n",
        "#   L(r_{1:T}) = \\prod_{t=1}^T L(r_t)\n",
        "#\n",
        "# Since a product is hard to compute precisely (all probabilities are < 0, so the product\n",
        "# will become very small), we just take the log of the likelihood:\n",
        "#\n",
        "#   log L(r_{1:T}) = \\sum_{t=1}^T log L(r_t)\n",
        "#\n",
        "# Before you continue coding, take a pen and paper and derive the log-likelihood formula\n",
        "# for the AR(1)-ARCH(1) model.\n",
        "#\n",
        "# Hint: Recall, in an AR(1) model, the mean prediction is \\mu_t = E_{t-1}(r_t) =\n",
        "#       E(\\alpha + \\beta * r_{t-1} + \\epsilon_t). The variance prediction of the ARCH(1)\n",
        "#       model is \\sigma_t^2 = E_{t-1}(\\epsilon_t^2) = E(a + b * \\epsilon_{t-1}^2).\n",
        "#       Plug these formulas into the equations above. Since you make each forecast for time t\n",
        "#       in t-1, you can use everything that is known in t-1 as an observed variable (i.e. not\n",
        "#       a random number any more.\n",
        "\n",
        "\n",
        "# Once you derived the log-likelihood formula, implement it in the function below. The function\n",
        "# should calculate the log-likelihood of the observed excess returns, given a set of parameters.\n",
        "#\n",
        "# Note: Since you need the first AR(1)-residual \\epsilon_1 for the variance forecast, skip\n",
        "#       the very first return in the actual log-likelihood calculation.\n",
        "# Hint: You can get \\pi as math.pi\n",
        "#\n",
        "mu_t = ar_model.params[0]+factors['rm_excess'][0:-1]*ar_model.params[1]\n",
        "\n",
        "def loglikelihood_ar_arch(parameters):   # Parameters is a list of model parameters, here: [\\alpha, \\beta, a, b]\n",
        "    ar_alpha = parameters[0]\n",
        "    ar_beta = parameters[1]\n",
        "    arch_a = parameters[2]\n",
        "    arch_b = parameters[3]\n",
        "    loglikeli = 0\n",
        "    for i in range(1,factors.shape[0]):\n",
        "      prob = -0.5*math.log(math.pi*2) - 0.5* math.log(arch_a + arch_b * ((ar_model_resid[i-1])**2)) - 0.5*(( rm_excess_x[i] - mu_t[i-1]))**2/(arch_a + arch_b * (ar_model_resid[i-1])**2)\n",
        "      loglikeli += prob\n",
        "\n",
        "    return -loglikeli  # We return the negative log-likelihood. This is intentional, you'll see in a moment, why.\n",
        "\n",
        "# Now you are ready to optimize the loglikelihood. Python provides a number of out-of-the-box\n",
        "# optimization algorithms in the scipy package. We will use the function scipy.optimize.minimize(...)\n",
        "# to perform the optimization. As its name suggests, the function minimizes some value. Since\n",
        "# we want to maximize the loglikelihood, we'll just minimize the negative loglikelihood.\n",
        "# That why we let the function above return the negative log-likelihood.\n",
        "#\n",
        "# Take a look at the function's documentation, especially at the examples on the bottom, to\n",
        "# see how to use the function:\n",
        "#   https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n",
        "#\n",
        "# Besides our objective function (which is the log-likelihood calculation function above), we\n",
        "# only need to define a starting value for the parameters to get the optimization started.\n",
        "# We just use the parameters estimates from the 2-pass OLS estimation above as starting\n",
        "# values.\n",
        "#\n",
        "# Hint: Use method = 'Nelder-Mead' in the scipy.optimize.minimize(...) function.\n",
        "# Hint: ar_arch_params_start should be a list with 4 elements.\n",
        "#\n",
        "\n",
        "ar_arch_params_start = [ar_model.params[0],ar_model.params[1],arch_model.params[0],arch_model.params[1]]\n",
        "bnds = ((0,None),(0,None),(0,None),(0,None))\n",
        "ar_arch_params = scipy.optimize.minimize(loglikelihood_ar_arch, ar_arch_params_start, method= 'Nelder-Mead',bounds=bnds)\n",
        "#ar_arch_params = scipy.optimize.minimize(loglikelihood_ar_arch,[0.0038,0.1030,0.0023,0.1017 ] ,method= 'Nelder-Mead')\n",
        "\n",
        "# Given the optimal model parameters, compute the volatility (!) forecast of the model.\n",
        "#\n",
        "\n",
        "arch_vol_forecasts =  ar_arch_params.x[2] + ar_arch_params.x[3] * squared_resid   # Hint: type(arch_vol_forecasts) should be np.ndarray and arch_vol_forecasts.shape should be (616,)\n",
        "\n",
        "\n",
        "# Now, let's plot the vol forecasts\n",
        "fig, ax = plt.subplots(2, 1)\n",
        "ax[0].plot(factors['date'].iloc[2:], factors['rm_excess'].iloc[2:])\n",
        "ax[0].set_title(\"Market excess returns\")\n",
        "ax[1].plot(factors['date'].iloc[2:], arch_vol_forecasts)\n",
        "ax[1].set_title(\"One-day ahead daily vol forecast (ARCH model)\")\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/_minimize.py:522: RuntimeWarning: Method Nelder-Mead cannot handle constraints nor bounds.\n",
            "  RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f94eda87f9ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mar_arch_params_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0march_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0march_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mbnds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mar_arch_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglikelihood_ar_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_arch_params_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Nelder-Mead'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m#ar_arch_params = scipy.optimize.minimize(loglikelihood_ar_arch,[0.0038,0.1030,0.0023,0.1017 ] ,method= 'Nelder-Mead')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfxr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mfsim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mxe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0mfxe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfxe\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mfxr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-f94eda87f9ca>\u001b[0m in \u001b[0;36mloglikelihood_ar_arch\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloglikeli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march_a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0march_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_model_resid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrm_excess_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march_a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0march_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mar_model_resid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mloglikeli\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: math domain error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5DJqmExw0Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 3: MLE estimation of AR(1)-GARCH(1, 1) model\n",
        "# -------------------------------------------------\n",
        "\n",
        "# The GARCH model is similar to the ARCH model, but also makes the variance forecast for\n",
        "# tomorrow depend on the variance forecast of today:\n",
        "#    \\sigma_t^2 = a + b * \\epsilon_{t-1}^2 + c * \\sigma_{t-1}^2\n",
        "#\n",
        "# Write a function that calculates the time series for \\sigma_t based on given parameters\n",
        "# a, b, c, an initial value for \\sigma^2 and a time series of epsilon_t.\n",
        "#\n",
        "# Hint: Use a for-loop.\n",
        "# Note: Do not create a \\sigma^2 estimate based on the last \\epsilon observation. This would\n",
        "#       create a forecast for the first return after our observed data sample. We don't want that.\n",
        "#\n",
        "\n",
        "def garch_variance(a, b, c, sigma_initial, epsilon):\n",
        "    sigma2 =\n",
        "    return sigma2\n",
        "\n",
        "test_garch_variance =                            # Hint: type(test_garch_variance) should be np.ndarray\n",
        "                                                 # Hint: test_garch_variance.shape should be (616,)\n",
        "\n",
        "# How write a function that calculates the log-likelihood of excess returns in an AR(1)-GARCH(1,1) model\n",
        "# based on the variance forecast of the GARCH model. Follow the same reasoning\n",
        "# and procedure as for the ARCH model above.\n",
        "#\n",
        "def loglikelihood_ar_garch(parameters):\n",
        "    ar_alpha = parameters[0]\n",
        "    ar_beta = parameters[1]\n",
        "    garch_a = parameters[2]\n",
        "    garch_b = parameters[3]\n",
        "    garch_c = parameters[4]\n",
        "    garch_initial_sigma = parameters[5]\n",
        "\n",
        "    loglikeli =\n",
        "\n",
        "    return -loglikeli  # We return the negative log-likelihood. This is intentional, you'll see in a moment, why.\n",
        "\n",
        "# Now, again, use the scipy.optimize.minimize function to find the optimal\n",
        "# parameters of the AR(1)-GARCH(1,1) model.\n",
        "#\n",
        "# Again, use method = 'Nelder-Mead' in the scipy.optimize.minimize(...) function.\n",
        "#\n",
        "ar_garch_params_start = [ar_model.params[0], ar_model.params[1], 0.0001, 0.15, 0.8, np.var(factors['rm_excess'])]\n",
        "ar_garch_params =\n",
        "\n",
        "# Given the optimal model parameters, compute the volatility (!) forecast of the GARCH(1,1) model.\n",
        "#\n",
        "\n",
        "garch_vol_forecasts =       # Hint: type(garch_vol_forecasts) should be np.ndarray and garch_vol_forecasts.shape should be (616,)\n",
        "\n",
        "# Now, let's plot the vol forecasts\n",
        "fig, ax = plt.subplots(2, 1)\n",
        "ax[0].plot(factors['date'].iloc[2:], factors['rm_excess'].iloc[2:])\n",
        "ax[0].set_title(\"Market excess returns\")\n",
        "ax[1].plot(factors['date'].iloc[2:], arch_vol_forecasts, label = 'ARCH model vol forecast')\n",
        "ax[1].plot(factors['date'].iloc[2:], garch_vol_forecasts, label = 'GARCH model vol forecast')\n",
        "ax[1].set_title(\"One-day ahead daily vol forecast\")\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}